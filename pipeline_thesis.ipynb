{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract keypoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detection model is centernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utils.utils import get_face_points, normalize_wrt_maximum_distance_point, get_torso_points\n",
    "from utils.img_utils import draw_key_points_pose, draw_axis\n",
    "from utils.utils_tflite import initialize_interpreter, resize_preserving_ar, inference_interpreter, pose_from_det\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mload_data\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_creation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data, calculate_stats_in_dataset\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#from models.models import *\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_body\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \u001b[38;5;66;03m# new\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\General_fold\\Thesis code\\Personal_code\\load_data\\dataset_creation.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mload_data\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgt_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_ground_truth\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mload_data\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkpts_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_kpts_from_json\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_stats_in_dataset\u001b[39m(data):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# extract the 2,5,8,11,14\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\General_fold\\Thesis code\\Personal_code\\load_data\\kpts_loader.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpose\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_kpts_from_json\u001b[39m(input_file_path: os\u001b[38;5;241m.\u001b[39mPathLike, extended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) :\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pose'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from exceptions import *\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from load_data.dataset_creation import load_data, calculate_stats_in_dataset\n",
    "#from models.models import *\n",
    "from models.model_body import * # new\n",
    "from models.losses import *\n",
    "from models.metric import *\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(r\"..\\07\\07\\free_1_ID07\\RGB\\000464_RGB.png\")\n",
    "im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "print(im_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = im_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model_path = r\"../HHP-Net/centernet/centernet_mobilenetv2_fpn_od/model.tflite\"\n",
    "interpreter_od, input_shape_model_od, input_details_od = initialize_interpreter(detection_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model_path = r\"../HHP-Net/posenet/posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\"\n",
    "interpreter_pose, input_shape_interpreter_pose, input_details_pose = initialize_interpreter(pose_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 140, (320, 180))\n"
     ]
    }
   ],
   "source": [
    "resized_img, new_old_shape = resize_preserving_ar(img, input_shape_model_od)\n",
    "print(new_old_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "print(resized_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, classes, scores, num_det = inference_interpreter(interpreter_od, resized_img, input_details_od)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpt = pose_from_det(resized_img, boxes, classes, scores, interpreter_pose, input_shape_interpreter_pose, input_details_pose, img, new_old_shape, False, 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.25, 0.3125, 1.0],\n",
       "  [1.261111111111111, 0.296875, 1.0],\n",
       "  [1.238888888888889, 0.290625, 1.0],\n",
       "  [1.1333333333333333, 0.36875, 0.0],\n",
       "  [1.1444444444444444, 0.275, 1.0],\n",
       "  [1.1388888888888888, 0.378125, 1.0],\n",
       "  [0.95, 0.30625, 1.0],\n",
       "  [1.1, 0.41875, 0.0],\n",
       "  [0.7833333333333333, 0.35, 1.0],\n",
       "  [1.0722222222222222, 0.4625, 1.0],\n",
       "  [0.7722222222222223, 0.465625, 1.0],\n",
       "  [1.0055555555555555, 0.471875, 1.0],\n",
       "  [0.8444444444444444, 0.459375, 1.0],\n",
       "  [1.0777777777777777, 0.5625, 0.0],\n",
       "  [0.7944444444444444, 0.5625, 0.0],\n",
       "  [0.7777777777777778, 0.46875, 0.0],\n",
       "  [0.8277777777777777, 0.5625, 0.0]]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_res = img.copy()\n",
    "for kpt_person in kpt:\n",
    "        for elem in kpt_person:\n",
    "            elem[0] = elem[0] * img.shape[0]\n",
    "            elem[1] = elem[1] * img.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pose_id_part_centernet = {\n",
    "    0:  \"Nose\",\n",
    "    1:  \"Neck\",\n",
    "    2:  \"RShoulder\",\n",
    "    3:  \"RElbow\",\n",
    "    4:  \"RWrist\",\n",
    "    5:  \"LShoulder\",\n",
    "    6:  \"LElbow\",\n",
    "    7:  \"LWrist\",\n",
    "    8:  \"MidHip\",\n",
    "    9:  \"RHip\",\n",
    "    10: \"RKnee\",\n",
    "    11: \"RAnkle\",\n",
    "    12: \"LHip\",\n",
    "    13: \"LKnee\",\n",
    "    14: \"LAnkle\",\n",
    "    15: \"REye\",\n",
    "    16: \"LEye\",\n",
    "    17: \"REar\",\n",
    "    18: \"LEar\",\n",
    "    19: \"LBigToe\",\n",
    "    20: \"LSmallToe\",\n",
    "    21: \"LHeel\",\n",
    "    22: \"RBigToe\",\n",
    "    23: \"RSmallToe\",\n",
    "    24: \"RHeel\",\n",
    "    25: \"Background\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " But from the https://github.com/CMU-Perceptual-Computing-Lab/openpose_train/issues/20\n",
    " \n",
    " {0,  \"Nose\"},\n",
    "        {1,  \"LEye\"},\n",
    "        {2,  \"REye\"},\n",
    "        {3,  \"LEar\"},\n",
    "        {4,  \"REar\"},\n",
    "        {5,  \"LShoulder\"},\n",
    "        {6,  \"RShoulder\"},\n",
    "        {7,  \"LElbow\"},\n",
    "        {8,  \"RElbow\"},\n",
    "        {9,  \"LWrist\"},\n",
    "        {10, \"RWrist\"},\n",
    "        {11, \"LHip\"},\n",
    "        {12, \"RHip\"},\n",
    "        {13, \"LKnee\"},\n",
    "        {14, \"RKnee\"},\n",
    "        {15, \"LAnkle\"},\n",
    "        {16, \"RAnkle\"},\n",
    "        {17, \"UpperNeck\"},\n",
    "        {18, \"HeadTop\"},\n",
    "        {19, \"LBigToe\"},\n",
    "        {20, \"LSmallToe\"},\n",
    "        {21, \"LHeel\"},\n",
    "        {22, \"RBigToe\"},\n",
    "        {23, \"RSmallToe\"},\n",
    "        {24, \"RHeel\"},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pose_id_part_openpose = {\n",
    "    0:  \"Nose\",\n",
    "    1:  \"Neck\",\n",
    "    2:  \"RShoulder\",\n",
    "    3:  \"RElbow\",\n",
    "    4:  \"RWrist\",\n",
    "    5:  \"LShoulder\",\n",
    "    6:  \"LElbow\",\n",
    "    7:  \"LWrist\",\n",
    "    8:  \"MidHip\",\n",
    "    9:  \"RHip\",\n",
    "    10: \"RKnee\",\n",
    "    11: \"RAnkle\",\n",
    "    12: \"LHip\",\n",
    "    13: \"LKnee\",\n",
    "    14: \"LAnkle\",\n",
    "    15: \"REye\",\n",
    "    16: \"LEye\",\n",
    "    17: \"REar\",\n",
    "    18: \"LEar\",\n",
    "    19: \"LBigToe\",\n",
    "    20: \"LSmallToe\",\n",
    "    21: \"LHeel\",\n",
    "    22: \"RBigToe\",\n",
    "    23: \"RSmallToe\",\n",
    "    24: \"RHeel\",\n",
    "    25: \"Background\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kpt_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_kpt = get_face_points(kpt_person, 'centernet')\n",
    "torso_kpt = get_torso_points(kpt_person, 'centernet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1350.0, 600.0, 1.0],\n",
       " [1362.0, 570.0, 1.0],\n",
       " [1338.0, 558.0, 1.0],\n",
       " [1224.0, 708.0, 0.0],\n",
       " [1236.0, 528.0, 1.0],\n",
       " [1230.0, 726.0, 1.0],\n",
       " [1026.0, 588.0, 1.0],\n",
       " [1188.0, 804.0, 0.0],\n",
       " [846.0, 672.0, 1.0],\n",
       " [1158.0, 888.0, 1.0],\n",
       " [834.0, 894.0, 1.0],\n",
       " [1086.0, 906.0, 1.0],\n",
       " [912.0, 882.0, 1.0],\n",
       " [1164.0, 1080.0, 0.0],\n",
       " [858.0, 1080.0, 0.0],\n",
       " [840.0, 900.0, 0.0],\n",
       " [893.9999999999999, 1080.0, 0.0]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpt_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1230.0, 726.0, 1.0, 1026.0, 588.0, 1.0, 1086.0, 906.0, 1.0, 912.0, 882.0, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torso_kpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x_face = np.mean([face_kpt[i] for i in range(0, 15, 3) if face_kpt[i] != 0.0])\n",
    "mean_y_face = np.mean([face_kpt[i + 1] for i in range(0, 15, 3) if face_kpt[i + 1] != 0.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x_torso = np.mean([torso_kpt[i] for i in range(0, 12, 3) if torso_kpt[i] != 0.0])\n",
    "mean_y_torso = np.mean([torso_kpt[i + 1] for i in range(0, 12, 3) if torso_kpt[i + 1] != 0.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_kpt_normalized = np.array(normalize_wrt_maximum_distance_point(face_kpt, mean_x_face, mean_y_face))\n",
    "torso_kpt_normalized = np.array(normalize_wrt_maximum_distance_point(torso_kpt, mean_x_torso, mean_y_torso))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torso_kpt_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.72727275  0.11111111  1.          0.90909094 -0.35185185  1.\n",
      "   0.54545456 -0.537037    1.          0.          0.          0.\n",
      "  -1.         -1.          1.        ]], shape=(1, 15), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1.         -0.264       1.         -0.22522523 -1.          1.\n",
      "   0.13513513  0.696       1.         -0.9099099   0.568       1.        ]], shape=(1, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_kpts_face = tf.cast(np.expand_dims(face_kpt_normalized, 0), tf.float32)\n",
    "print(input_kpts_face)\n",
    "\n",
    "input_kpts_torso = tf.cast(np.expand_dims(torso_kpt_normalized, 0), tf.float32)\n",
    "print(input_kpts_torso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we have keypoints for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lshoulder, Rshoulder, Lelbow, Relbow, Lwrist, Rwrist, Lhip, Rhip\n",
    "#Lshoulder, Rshoulder, Lhip, Rhip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the center for torso will be intersection of diagonal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from exceptions import *\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from load_data.dataset_creation import load_data, calculate_stats_in_dataset\n",
    "#from models.models import *\n",
    "from models.model_body import * # new\n",
    "from models.losses import *\n",
    "from models.metric import *\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class PRE_PROCESS_NETWORK(Enum):\n",
    "    CENTERNET = 'kpts_centernet_super_new'\n",
    "    OPENPOSE = 'kpts_openpose'\n",
    "    MEDIAPIPE = 'kpts_mediapipe'\n",
    "    ALPHAPOSE = 'kpts_alphapose' #new\n",
    "    # PRE_PROCESS_NETWORK.MEDIAPIPE.name\n",
    "    # PRE_PROCESS_NETWORK.MEDIAPIPE.value\n",
    "    # repr(PRE_PROCESS_NETWORK.MEDIAPIPE)\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-e\", \"--epochs\", type=int, default=250, help=\"epochs to train\", required=False)\n",
    "    ap.add_argument(\"-a\", \"--all-dataset\", type=bool, default=True, help=\"This flag allow to load a small portion of the data\", required=False)\n",
    "    ap.add_argument(\"-s\", \"--save-model\", type=bool, default=True,\n",
    "                    help=\"If the trained model would be saved or not\", required=False)\n",
    "    ap.add_argument(\"-em\", \"--extraction-model\", type=str,\n",
    "                    help=\"This flag allow to load_data preprocessed with the required network\", required=True)\n",
    "    ap.add_argument(\"-ex\", \"--extended-model\", default=False,\n",
    "                    help=\"Flag to use 33 kpts from mediapipe\", required=False, action=\"store_true\")\n",
    "    # ap.add_argument(\"--centernet\", help=\"Chose mediapipe as kpts folder\", required=False, action='store_const', const=PRE_PROCESS_NETWORK.CENTERNET)\n",
    "    # ap.add_argument(\"--openpose\", help=\"Chose mediapipe as kpts folder\", required=False, action='store_const', const=PRE_PROCESS_NETWORK.OPENPOSE)\n",
    "    # ap.add_argument(\"--mediapipe\", help=\"Chose mediapipe as kpts folder\", required=False, action='store_const', const=PRE_PROCESS_NETWORK.MEDIAPIPE)\n",
    "    #\n",
    "    config = ap.parse_args()\n",
    "    # # to have a validation appply StratifiedShuffleSplit() on test\n",
    "    #\n",
    "    # print(f'all dataset = {config.all_dataset}')\n",
    "    # print(f'model = {config}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    SERVER = False\n",
    "    ALL_DATASET = config.all_dataset  # useful for debug\n",
    "    EPOCHS = config.epochs\n",
    "    TRIALS = 1\n",
    "    EXTENDED = False\n",
    "    SAVE_MODEL = config.save_model\n",
    "    match (config.extraction_model.lower()):\n",
    "        case 'centernet':\n",
    "            KPTS_EXTRACTOR = PRE_PROCESS_NETWORK.CENTERNET\n",
    "        case 'mediapipe':\n",
    "            KPTS_EXTRACTOR = PRE_PROCESS_NETWORK.MEDIAPIPE\n",
    "            EXTENDED = config.extended_model\n",
    "        case 'openpose':\n",
    "            KPTS_EXTRACTOR = PRE_PROCESS_NETWORK.OPENPOSE\n",
    "        case 'alphapose': # new\n",
    "            KPTS_EXTRACTOR = PRE_PROCESS_NETWORK.ALPHAPOSE #new\n",
    "        case _:\n",
    "            raise NotImplementedError('Check spelling of input values')\n",
    "    # KPTS_EXTRACTOR = PRE_PROCESS_NETWORK.CENTERNET\n",
    "\n",
    "\n",
    "    print(f'\\n SERVER {SERVER}, ALL_DATASET = {ALL_DATASET}, \\n EPOCHS = {EPOCHS}, TRIALS = {TRIALS}\\n KPTS_EXTRACTOR = {KPTS_EXTRACTOR.name}\\n EXTENDED = {EXTENDED}')\n",
    "\n",
    "\n",
    "    if SERVER:\n",
    "        kpts_path = Path('/media/DATA/Datasets/BIWI_processed/') / KPTS_EXTRACTOR.value\n",
    "        print(f'kpts path ={kpts_path}')\n",
    "        angles_gt = Path('/media/DATA/Datasets/BIWI/db_annotations')\n",
    "    else:\n",
    "        kpts_path = Path(r\"../07/07_processed\") / KPTS_EXTRACTOR.value\n",
    "        angles_gt = Path('../07/07_annotations')\n",
    "\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # try:\n",
    "        #     tf.config.experimental.set_virtual_device_configuration(gpus[0], [\n",
    "        #         tf.config.experimental.VirtualDeviceConfiguration(memory_limit=000)])\n",
    "        # except RuntimeError as e:\n",
    "        #     print(e)\n",
    "\n",
    "    # create folder for results\n",
    "    current_time = datetime.datetime.now()\n",
    "    today = datetime.date.today()\n",
    "    d1 = '' + today.strftime(\"%d-%m-%Y\") + '_' + str(current_time.hour) + '_' + str(current_time.minute)+'_'+str(KPTS_EXTRACTOR.name)\n",
    "    folder_results = Path('/Tensorboard/HPE-Net')\n",
    "    folder_results = folder_results / d1\n",
    "    if not folder_results.is_dir():\n",
    "        folder_results.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "    try:\n",
    "        my_data, my_gt, groups = load_data(kpts_path=kpts_path, angles_gt=angles_gt, server=SERVER,\n",
    "                                           all_data=ALL_DATASET, extended=EXTENDED)\n",
    "    except IncorrectInputValue:\n",
    "        print('data ot gt path are incorrect')\n",
    "        sys.exit(2)\n",
    "    mean_uncertainty_in_dataset, std_uncertainty_in_dataset = calculate_stats_in_dataset(my_data)\n",
    "    print(f'\\nUNCERTAINTY: mean = {mean_uncertainty_in_dataset},  var = {std_uncertainty_in_dataset}\\n')\n",
    "\n",
    "    log_dir = \"/Tensorboard/HPE-Net/logs/fit/\" + datetime.datetime.now().strftime(\n",
    "            \"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "                # Stop training when `val_loss` is no longer improving\n",
    "                monitor=\"val_loss\",\n",
    "                # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "                min_delta=0.001, # almost everythinh is an improvemente\n",
    "                # \"no longer improving\" being further defined as \"for at least 5 epochs\"\n",
    "                patience=5,\n",
    "                verbose=1,\n",
    "                restore_best_weights = False, # take the weights 5 epochs after best\n",
    "        )\n",
    "\n",
    "    # my_data = np.ones([100,15], dtype=float)\n",
    "    # my_gt = np.asarray(tf.cast(np.ones([100,2], dtype=float), dtype=tf.float32))\n",
    "    # my_gt = np.ones([100, 2], dtype=float)\n",
    "    # groups = np.ones([100], dtype=float)\n",
    "    # groups[35:70] = 2 * groups[35:70]\n",
    "    # groups[70:] = 3 * groups[70:]\n",
    "\n",
    "    # my_model.summary()\n",
    "    # keras.utils.plot_model(my_model, \"/media/DATA/Users/Federico/my_first_model_with_shape_info.png\", show_shapes=True)\n",
    "\n",
    "    my_results = {}\n",
    "    my_results['yaw_MAE_hpe'] = []\n",
    "    my_results['pitch_MAE_hpe'] = []\n",
    "    my_results['roll_MAE_hpe'] = []\n",
    "\n",
    "    # https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators\n",
    "    # SS = GroupShuffleSplit(n_splits=5, test_size=0.20, random_state=0)\n",
    "    # for train_index, test_index in SS.split(my_data, groups=groups):\n",
    "    i=0\n",
    "    slicer = GroupShuffleSplit(n_splits=10, random_state=i, train_size=18)\n",
    "\n",
    "    for train_index, test_index in slicer.split(my_data, my_gt, groups):\n",
    "        X_train, X_test = my_data[train_index], my_data[test_index]\n",
    "        y_train, y_test = my_gt[train_index], my_gt[test_index]\n",
    "        if EXTENDED:\n",
    "            print('EXTENDED model')\n",
    "            my_model = hhp_net_body(mean=mean_uncertainty_in_dataset, std=std_uncertainty_in_dataset, alpha=1, only_hands = False) # new it was extended\n",
    "        else:\n",
    "            my_model = hhp_net_body(mean=mean_uncertainty_in_dataset, std=std_uncertainty_in_dataset, alpha=1)\n",
    "\n",
    "        # dataset circa 17'000 examples\n",
    "        # to start decaying at 50th epochs\n",
    "        # 50 * (num_samples_of_whole_dataset / batch_size) = 50*(17000/100)= 8500\n",
    "        lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=1e-3,\n",
    "                decay_steps=1000, # new\n",
    "                decay_rate=0.5,\n",
    "                staircase=True)\n",
    "\n",
    "        my_model.compile(\n",
    "                optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),  # Optimizer\n",
    "                # Loss function to minimize\n",
    "                loss=[Mse_loss_single_output_with_uncertainty(), Mse_loss_single_output_with_uncertainty(),\n",
    "                      Mse_loss_single_output_with_uncertainty()],\n",
    "                # List of metrics to monitor\n",
    "                # metrics=[keras.metrics.MeanSquaredError()],\n",
    "                metrics={'yaw'  : [Mean_Absolute_Error_HPE(), Save_Uncertainty_deg()],\n",
    "                         'pitch': [Mean_Absolute_Error_HPE(), Save_Uncertainty_deg()],\n",
    "                         'roll' : [Mean_Absolute_Error_HPE(), Save_Uncertainty_deg()]},\n",
    "                # metrics = {'yaw': keras.metrics.MeanSquaredError(), 'pitch': keras.metrics.MeanSquaredError(), 'roll': keras.metrics.MeanSquaredError()},\n",
    "        )\n",
    "\n",
    "        my_model.summary()\n",
    "        # keras.utils.plot_model(my_model, \"/media/DATA/Users/Federico/my_first_model_with_shape_info.png\", show_shapes=True)\n",
    "        print('\\n')\n",
    "        print(f\"TRAINING {i}---------------\")\n",
    "\n",
    "        # print(\"tarin indexes %s\\ntest indexes %s\\n\" % (train_index, test_index))\n",
    "        print(f'groups for training{np.unique(groups[train_index])}\\ngroups for test {np.unique(groups[test_index])}')\n",
    "\n",
    "        # print(f'X_train.shape = {X_train.shape}')  # = (num_samples,15)\n",
    "        # print(f'y_train.shape = {y_train.shape}')  # = (num_samples,2)\n",
    "        #\n",
    "        # print(f'X_test.shape = {X_test.shape}')  # = (num_samples,15)\n",
    "        # print(f'y_test.shape = {y_test.shape}')  # = (num_samples,2)\n",
    "\n",
    "        # train_dataset = tf.data.Dataset.from_tensor_slices((X_train, (y_train, y_train, y_train)))\n",
    "        # test_dataset = tf.data.Dataset.from_tensor_slices((X_test, (y_test, y_test, y_test)))\n",
    "        # {\"a\": [1, 2], \"b\": [3, 4]}\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(({'input': X_train, }, {'yaw'  : y_train[:, [0]].squeeze(),\n",
    "                                                                                   'pitch': y_train[:, [1]].squeeze(),\n",
    "                                                                                   'roll' : y_train[:, [2]].squeeze()}))\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(({'input': X_test, }, {'yaw'  : y_test[:, [0]].squeeze(),\n",
    "                                                                                 'pitch': y_test[:, [1]].squeeze(),\n",
    "                                                                                 'roll' : y_test[:, [2]].squeeze()}))\n",
    "\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=300, reshuffle_each_iteration=True) # new it was 5000\n",
    "\n",
    "        # print(f'test_dataset ')\n",
    "        # print(list(test_dataset.as_numpy_iterator())[:2])\n",
    "\n",
    "        BATCH_SIZE = 64\n",
    "        train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "        test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "        # print(f'test_dataset batchsized ')\n",
    "        # print(list(test_dataset.as_numpy_iterator())[:2])\n",
    "\n",
    "        history = my_model.fit(train_dataset, epochs=EPOCHS,\n",
    "                               callbacks=[tensorboard_callback, early_stopping_callback], validation_data=test_dataset\n",
    "                               )\n",
    "\n",
    "        print('\\n')\n",
    "        print(f\"EVALUATION {i}---------------\")\n",
    "\n",
    "        # print(f'result: yaw, pitch, roll \\n{y_test[0:10]}')\n",
    "        # print(  my_model(X_test[0:10], training=False))\n",
    "\n",
    "        results = my_model.evaluate(test_dataset, return_dict=True)\n",
    "\n",
    "        my_results['yaw_MAE_hpe'].append(results['yaw_MAE_hpe'])\n",
    "        my_results['pitch_MAE_hpe'].append(results['pitch_MAE_hpe'])\n",
    "        my_results['roll_MAE_hpe'].append(results['roll_MAE_hpe'])\n",
    "\n",
    "        hist_df = pd.DataFrame(history.history)\n",
    "\n",
    "        my_dictionary = {'random state'  : i, 'results': results, 'batch size': BATCH_SIZE,\n",
    "                         'KPTS_EXTRACTOR': KPTS_EXTRACTOR.name, 'training':str(np.unique(groups[train_index])), 'test':str(np.unique(groups[test_index]))}\n",
    "        my_result_file = folder_results / f'Training_logs_{i}.json'\n",
    "        with open(str(my_result_file), 'w') as f:\n",
    "            json.dump(my_dictionary, f)\n",
    "        hist_json_file = folder_results / f'history_{i}.csv'\n",
    "        with open(hist_json_file, mode='w') as f:\n",
    "            hist_df.to_csv(f)\n",
    "\n",
    "\n",
    "        if SAVE_MODEL:\n",
    "            my_model.save(folder_results / f'hpe_net_{KPTS_EXTRACTOR.name}_{i}')\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "    print('\\n')\n",
    "    print(\n",
    "        f'\\n SERVER {SERVER}, ALL_DATASET = {ALL_DATASET}, \\n EPOCHS = {EPOCHS}, TRIALS = {TRIALS}\\n KPTS_EXTRACTOR = {KPTS_EXTRACTOR.name}\\n')\n",
    "    print(f\"FINAL REUSLT ---------------\")\n",
    "    print(my_results)\n",
    "\n",
    "    mae_file = folder_results / f'MAE.csv'\n",
    "    df_results = pd.DataFrame(my_results)\n",
    "    with open(mae_file, mode='w') as f:\n",
    "        df_results.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
